{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcbba173-dad1-4f16-a897-002625d699dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\comra\\AppData\\Local\\Temp\\ipykernel_49856\\3525091844.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Tags\"].replace(\"\", np.nan, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Dataset\n",
    "df = pd.read_csv(\"E:\\\\Datasets\\\\PoetryFoundationData.csv\")  \n",
    "\n",
    "df[\"Tags\"].replace(\"\", np.nan, inplace=True)\n",
    "df[\"Theme\"] = df[\"Tags\"].fillna(\"\")\n",
    "\n",
    "df.to_csv(\"E:\\\\Datasets\\\\unlabeled_poems.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "892b9ca3-883a-4206-bc0c-878b319e6984",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13854 entries, 0 to 13853\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Title   13854 non-null  object\n",
      " 1   Poem    13854 non-null  object\n",
      " 2   Theme   13854 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 324.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " ['Money  Economics',\n",
       "  'Gratitude  Apologies',\n",
       "  'Infatuation  Crushes',\n",
       "  'Judaism',\n",
       "  'Growing Old',\n",
       "  'Social Commentaries',\n",
       "  'Marriage  Companionship',\n",
       "  'Humor  Satire',\n",
       "  'Thanksgiving',\n",
       "  'Horror',\n",
       "  'Gardening',\n",
       "  'Memorial Day',\n",
       "  'Infancy',\n",
       "  'Labor Day',\n",
       "  'Animals',\n",
       "  'Travels  Journeys',\n",
       "  'Get Well  Recovery',\n",
       "  'Health  Illness',\n",
       "  'Cinco de Mayo',\n",
       "  'Toasts  Celebrations',\n",
       "  'Ghosts  the Supernatural',\n",
       "  'Reading  Books',\n",
       "  'The Spiritual',\n",
       "  'Christianity',\n",
       "  'Heartache  Loss',\n",
       "  'Romantic Love',\n",
       "  'Relationships',\n",
       "  'First Love',\n",
       "  'Greek  Roman Mythology',\n",
       "  'Rivers',\n",
       "  'Friends  Enemies',\n",
       "  'Music',\n",
       "  'Gay',\n",
       "  'Unrequited Love',\n",
       "  'Heavens',\n",
       "  'Sciences',\n",
       "  'Race  Ethnicity',\n",
       "  'Winter',\n",
       "  'Queer',\n",
       "  'Graduation',\n",
       "  'Funerals',\n",
       "  'Islam',\n",
       "  'Home Life',\n",
       "  'Anniversary',\n",
       "  'Streams',\n",
       "  'Heroes  Patriotism',\n",
       "  'Engagement',\n",
       "  'Popular Culture',\n",
       "  'Architecture  Design',\n",
       "  'Other Religions',\n",
       "  'Independence Day',\n",
       "  'Christmas',\n",
       "  'Indoor Activities',\n",
       "  'Hanukkah',\n",
       "  'Farewells  Good Luck',\n",
       "  'Fairytales  Legends',\n",
       "  'Lesbian',\n",
       "  'Arts  Sciences',\n",
       "  'Trees  Flowers',\n",
       "  'Summer',\n",
       "  'Youth',\n",
       "  'The Body',\n",
       "  'Class',\n",
       "  'Buddhism',\n",
       "  'History  Politics',\n",
       "  'St Patricks Day',\n",
       "  'Fathers Day',\n",
       "  'School  Learning',\n",
       "  'Desire',\n",
       "  'Seas',\n",
       "  'God  the Divine',\n",
       "  'Midlife',\n",
       "  'Mythology  Folklore',\n",
       "  'Passover',\n",
       "  'Birthdays',\n",
       "  'Cities  Urban Life',\n",
       "  'Kwanzaa',\n",
       "  'Valentines Day',\n",
       "  'Coming of Age',\n",
       "  'Rosh Hashanah',\n",
       "  'Pets',\n",
       "  'Breakups  Vexed Love',\n",
       "  'Living',\n",
       "  'War  Conflict',\n",
       "  'Classic Love',\n",
       "  'Activities',\n",
       "  'Poetry  Poets',\n",
       "  'Men  Women',\n",
       "  'Easter',\n",
       "  'Town  Country Life',\n",
       "  'Sports  Outdoor Activities',\n",
       "  'Realistic  Complicated',\n",
       "  'Fall',\n",
       "  'New Year',\n",
       "  'Nature',\n",
       "  'Planets',\n",
       "  'Theater  Dance',\n",
       "  'Love',\n",
       "  'Gender  Sexuality',\n",
       "  'Birth',\n",
       "  'Birth  Birthdays',\n",
       "  'Crime  Punishment',\n",
       "  'Faith  Doubt',\n",
       "  'Disappointment  Failure',\n",
       "  'The Mind',\n",
       "  'Photography  Film',\n",
       "  'Parenthood',\n",
       "  'Philosophy',\n",
       "  'Language  Linguistics',\n",
       "  'Death',\n",
       "  'Time  Brevity',\n",
       "  'Yom Kippur',\n",
       "  'Life Choices',\n",
       "  'Stars',\n",
       "  'Halloween',\n",
       "  'Spring',\n",
       "  'Family  Ancestors',\n",
       "  'Separation  Divorce',\n",
       "  'Religion',\n",
       "  'Ramadan',\n",
       "  'Jobs  Working',\n",
       "  'Painting  Sculpture',\n",
       "  'Sorrow  Grieving',\n",
       "  'September 11th',\n",
       "  'Mothers Day',\n",
       "  'Weather',\n",
       "  'Landscapes  Pastorals',\n",
       "  'Eating  Drinking',\n",
       "  'Weddings'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "import re\n",
    "\n",
    "df = pd.read_csv('E:\\\\Datasets\\\\unlabeled_poems.csv')  \n",
    "df_cleaned = df.drop(columns=[\"Unnamed: 0\", \"Tags\", \"Poet\"])\n",
    "\n",
    "# Clean\n",
    "df_cleaned[\"Title\"] = df_cleaned[\"Title\"].str.strip().str.replace(r\"\\r\\n|\\r|\\n\", \" \", regex=True)\n",
    "df_cleaned[\"Poem\"] = df_cleaned[\"Poem\"].str.strip().str.replace(r\"\\r\\n|\\r|\\n\", \" \", regex=True)\n",
    "df_cleaned[\"Theme\"] = df_cleaned[\"Theme\"].fillna(\"\").str.strip().str.replace(r\"\\r\\n|\\r|\\n\", \"\", regex=True)\n",
    "\n",
    "df_cleaned[\"Theme\"] = df_cleaned[\"Theme\"].apply(lambda x: x.split(\",\") if x else [])\n",
    "\n",
    "# Extract unique themes\n",
    "unique_themes_from_data = set(theme for themes in df_cleaned[\"Theme\"] for theme in themes)\n",
    "\n",
    "unique_themes_from_data = [re.sub(r'[^\\w\\s]', '', theme).strip() for theme in unique_themes_from_data]\n",
    "df_cleaned.info(), unique_themes_from_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccfd2068-cd8e-40c0-96d1-4fd69ef4c17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(179,\n",
       " ['Activities',\n",
       "  'Adventure',\n",
       "  'Ambition',\n",
       "  'Anger',\n",
       "  'Animals',\n",
       "  'Anniversary',\n",
       "  'Architecture  Design',\n",
       "  'Arts  Sciences',\n",
       "  'Beauty',\n",
       "  'Birth'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predefined_themes = [\n",
    "    \"Nature\", \"Love\", \"Sadness\", \"Hope\", \"War\", \"Friendship\", \"Philosophy\", \"Death\",\n",
    "    \"Happiness\", \"Dreams\", \"Seasons\", \"Family\", \"Loneliness\", \"Spirituality\", \"Fantasy\",\n",
    "    \"Courage\", \"Adventure\", \"Wisdom\", \"Loss\", \"Mystery\", \"Conflict\", \"Beauty\", \"Grief\",\n",
    "    \"Rebirth\", \"Regret\", \"Peace\", \"Self-Discovery\", \"Strength\", \"Trust\", \"Justice\", \"Innocence\",\n",
    "    \"Youth\", \"Anger\", \"Revenge\", \"Eternity\", \"Love Lost\", \"Change\", \"Identity\", \"Morality\",\n",
    "    \"Forgiveness\", \"Despair\", \"Hopefulness\", \"Light\", \"Darkness\", \"Enlightenment\", \"Ambition\",\n",
    "    \"Freedom\", \"Romance\", \"Self-Reflection\", \"Journey\", \"Tradition\", \"Existentialism\", \"Connection\",\n",
    "    \"Inspiration\", \"Imagination\", \"Wisdom\"\n",
    "]\n",
    "\n",
    "all_themes = list(set(predefined_themes).union(unique_themes_from_data))\n",
    "\n",
    "all_themes = sorted(set(all_themes))\n",
    "\n",
    "len(all_themes), all_themes[:10]  # Show first 10 themes for reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e07e0ce-f92f-4522-8fac-1acc451ffdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10319, 2580, device(type='cuda'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=all_themes)\n",
    "\n",
    "# Transform theme labels into binary vectors\n",
    "theme_matrix = mlb.fit_transform(df_cleaned[\"Theme\"])\n",
    "\n",
    "theme_df = pd.DataFrame(theme_matrix, columns=mlb.classes_)\n",
    "\n",
    "df_combined = pd.concat([df_cleaned[[\"Poem\"]], theme_df], axis=1)\n",
    "\n",
    "# Split dataset into known and unknown themes\n",
    "df_known = df_combined[df_cleaned[\"Theme\"].apply(len) > 0]  # Poems with themes\n",
    "df_unknown = df_combined[df_cleaned[\"Theme\"].apply(len) == 0]  # Poems without themes\n",
    "\n",
    "# Define dataset class for multi-label classification\n",
    "class MultiLabelPoemDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.max_length = max_length\n",
    "        self.poems = self.data['Poem'].values\n",
    "        self.labels = self.data.drop(columns=['Poem']).values  # All columns except 'Poem' are labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        poem = self.poems[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Tokenize the poem text\n",
    "        encoding = self.tokenizer(\n",
    "            poem,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Convert to tensor format\n",
    "        encoding = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        encoding['labels'] = torch.tensor(label, dtype=torch.float32)  # Multi-label binary vector\n",
    "        return encoding\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Prepare training dataset\n",
    "dataset = MultiLabelPoemDataset(df_known, tokenizer)\n",
    "\n",
    "# Split dataset for training and validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Define DataLoader for training\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Load model for multi-label classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(all_themes))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "len(train_dataset), len(val_dataset), device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7968671b-3581-42bb-b276-4cc11f9b7239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\comra\\anaconda3\\envs\\poetry-gen\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\comra\\AppData\\Local\\Temp\\ipykernel_19056\\1602893910.py:19: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: comradev73 (comradev73-vit) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.3s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\comra\\Dev\\PoetryGeneration\\wandb\\run-20250404_012902-0bt0pje7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/comradev73-vit/huggingface/runs/0bt0pje7' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/comradev73-vit/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/comradev73-vit/huggingface' target=\"_blank\">https://wandb.ai/comradev73-vit/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/comradev73-vit/huggingface/runs/0bt0pje7' target=\"_blank\">https://wandb.ai/comradev73-vit/huggingface/runs/0bt0pje7</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1932' max='1932' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1932/1932 47:41, Epoch 5/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.100840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>0.098118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.096370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.092778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.085100</td>\n",
       "      <td>0.089836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Complete! Model Saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=6,  # Increased to improve theme learning\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    save_steps=500,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the trained model\n",
    "model.save_pretrained('./multi_label_theme_classifier')\n",
    "tokenizer.save_pretrained('./multi_label_theme_classifier')\n",
    "\n",
    "print(\"Training Complete! Model Saved.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a0a404-7f2e-4737-84e2-b504379cf283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Classifying themes for poems...\n",
      "Theme classification completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"Loading model...\")\n",
    "theme_classifier = BertForSequenceClassification.from_pretrained(\"./multi_label_theme_classifier\", num_labels=len(all_themes)).to(device)\n",
    "theme_tokenizer = BertTokenizer.from_pretrained(\"./multi_label_theme_classifier\")\n",
    "\n",
    "# Dynamic threshold tuning function using Otsuâ€™s method\n",
    "def find_best_threshold(scores):\n",
    "    scores = np.array(scores).flatten()\n",
    "    best_thresh = 0.5  # Default\n",
    "    if len(scores) > 1:\n",
    "        hist, bin_edges = np.histogram(scores, bins=50)\n",
    "        best_thresh = bin_edges[np.argmax(hist)]  # Most frequent score as threshold\n",
    "    return min(max(best_thresh, 0.3), 0.6)  # Clamp between 0.3 - 0.6\n",
    "\n",
    "# Function to classify poem themes with optimized thresholding\n",
    "def classify_poem_themes(poem_text, max_length=256, top_k=3):\n",
    "    \n",
    "    inputs = theme_tokenizer(poem_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=max_length).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = theme_classifier(**inputs).logits\n",
    "\n",
    "    predicted_scores = torch.sigmoid(outputs).cpu().numpy()[0]\n",
    "\n",
    "    threshold = find_best_threshold(predicted_scores)\n",
    "\n",
    "    predicted_themes = [all_themes[i] for i, score in enumerate(predicted_scores) if score > threshold]\n",
    "\n",
    "    if not predicted_themes:\n",
    "        top_k_indices = np.argsort(predicted_scores)[-top_k:]\n",
    "        predicted_themes = [all_themes[i] for i in top_k_indices]\n",
    "\n",
    "    return predicted_themes\n",
    "\n",
    "print(\"Classifying themes for poems...\")\n",
    "# Apply classification to all poems\n",
    "df[\"Predicted_Themes\"] = df[\"Poem\"].apply(classify_poem_themes)\n",
    "\n",
    "# Save dataset with predicted themes\n",
    "df[[\"Poem\", \"Predicted_Themes\"]].to_csv(\"final_labeled_poems.csv\", index=False)\n",
    "\n",
    "print(\"Theme classification completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9af4aeb-e4fe-428e-8a4f-b1e9b003ecd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading theme classifier...\n",
      "ðŸŽ¯ Classifying poems into themes...\n",
      "\n",
      "âœ… Done! Labeled poems saved to: labelled_gutenberg_poems.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "poems_df = pd.read_csv(\"E:\\\\Datasets\\\\gutenberg_poems_cleaned.csv\")\n",
    "\n",
    "default_threshold = 0.45\n",
    "per_class_thresholds = {theme: default_threshold for theme in all_themes}\n",
    "\n",
    "print(\"Loading theme classifier...\")\n",
    "theme_classifier = BertForSequenceClassification.from_pretrained(\n",
    "    \"./multi_label_theme_classifier\", num_labels=len(all_themes)\n",
    ").to(device)\n",
    "theme_tokenizer = BertTokenizer.from_pretrained(\"./multi_label_theme_classifier\")\n",
    "\n",
    "def classify_poem_themes(poem_text, max_length=256, top_k=3):\n",
    "    poem_text = str(poem_text).strip()\n",
    "\n",
    "    if not poem_text:\n",
    "        return []  # skip this poem altogether or log it\n",
    "\n",
    "    inputs = theme_tokenizer(\n",
    "        poem_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=max_length\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = theme_classifier(**inputs).logits\n",
    "\n",
    "    scores = torch.sigmoid(outputs).cpu().numpy()[0]\n",
    "\n",
    "    predicted_themes = [\n",
    "        all_themes[i]\n",
    "        for i, score in enumerate(scores)\n",
    "        if score > per_class_thresholds.get(all_themes[i], default_threshold)\n",
    "    ]\n",
    "\n",
    "    if not predicted_themes:\n",
    "        top_k_indices = np.argsort(scores)[-top_k:]\n",
    "        predicted_themes = [all_themes[i] for i in top_k_indices]\n",
    "\n",
    "    common_themes = {\"Love\", \"Nature\", \"Death\", \"Hope\"}\n",
    "    rare_theme_indices = [i for i, t in enumerate(all_themes) if t not in common_themes]\n",
    "    rare_scores = [(i, scores[i]) for i in rare_theme_indices if scores[i] > (default_threshold - 0.1)]\n",
    "\n",
    "    if rare_scores:\n",
    "        top_rare_index = max(rare_scores, key=lambda x: x[1])[0]\n",
    "        rare_theme = all_themes[top_rare_index]\n",
    "        if rare_theme not in predicted_themes:\n",
    "            predicted_themes.append(rare_theme)\n",
    "\n",
    "    return list(set(predicted_themes))\n",
    "\n",
    "\n",
    "# Apply classifier to all poems\n",
    "print(\"Classifying poems into themes...\")\n",
    "poems_df[\"Themes\"] = poems_df[\"Poem\"].astype(str).apply(classify_poem_themes)\n",
    "\n",
    "# Save the labeled poems\n",
    "output_path = \"labelled_gutenberg_poems.csv\"\n",
    "poems_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nDone! Labeled poems saved to: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f6487e2-447c-47ea-84f9-ed78ca53b91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\comra\\anaconda3\\envs\\poetry-gen\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd2ff5e7a7749379a853d6eac2fa090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/13854 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import (\n",
    "    GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, \n",
    "    DataCollatorForLanguageModeling, EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "df = pd.read_csv(\"final_labeled_poems.csv\")\n",
    "\n",
    "df[\"Prompt\"] = df[\"Predicted_Themes\"].apply(lambda x: f\"<|theme|>: {', '.join(eval(x))}\\n<|poem|>: \")\n",
    "\n",
    "df[\"Training_Text\"] = df[\"Prompt\"] + df[\"Poem\"]\n",
    "\n",
    "dataset = Dataset.from_pandas(df[[\"Training_Text\"]])\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set pad token\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "model.to(device\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"Training_Text\"], \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a7fdf8b-6aa4-4459-9c0c-b6fe8a2fdad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\comra\\anaconda3\\envs\\poetry-gen\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\comra\\AppData\\Local\\Temp\\ipykernel_18860\\2576383961.py:21: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5196' max='5196' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5196/5196 2:44:45, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.362200</td>\n",
       "      <td>3.036869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.090100</td>\n",
       "      <td>2.955768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.006300</td>\n",
       "      <td>2.910091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.986500</td>\n",
       "      <td>2.879425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.935900</td>\n",
       "      <td>2.860819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.924200</td>\n",
       "      <td>2.853698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./poetry_gpt2\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=500,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets,\n",
    "    eval_dataset=tokenized_datasets,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "print(\"Training started...\")\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(\"./poetry_gpt2_finetuned\")\n",
    "tokenizer.save_pretrained(\"./poetry_gpt2_finetuned\")\n",
    "\n",
    "print(\"Training completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6b69112-4a63-475a-96b0-6f8e14010448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df = pd.read_csv(\"E:\\\\Datasets\\\\labeled_poems.csv\")\n",
    "\n",
    "def safe_parse_themes(x):\n",
    "    try:\n",
    "        themes = ast.literal_eval(x) if isinstance(x, str) else x\n",
    "        if isinstance(themes, list):\n",
    "            return \"|\".join(theme.strip() for theme in themes)\n",
    "        else:\n",
    "            return str(themes)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing: {x} â€” {e}\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "df['Themes'] = df['Themes'].apply(safe_parse_themes)\n",
    "\n",
    "df['Poem'] = df['Poem'].apply(lambda p: p.replace('\\r\\n', '\\n').replace('\\r', '\\n') if isinstance(p, str) else p)\n",
    "\n",
    "df['text'] = df.apply(lambda row: f\"Themes: {row['Themes']}\\nPoem:\\n{row['Poem']}\", axis=1)\n",
    "\n",
    "df[['text']].to_csv(\"poetry_text_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "762a2019-06e3-4c7e-943e-ade041ef37bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Themes: Living|Nature\\nPoem:\\n\\n\\nDog bone, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Themes: Living|Nature\\nPoem:\\n\\n\\nThe old cupo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Themes: Living|Nature\\nPoem:\\n\\n\\nLook for me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Themes: Living|Nature\\nPoem:\\n\\n\\nBehind the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Themes: Living|Relationships\\nPoem:\\n\\n\\nWhen ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Themes: Living|Nature\\nPoem:\\n\\n\\nDog bone, st...\n",
       "1  Themes: Living|Nature\\nPoem:\\n\\n\\nThe old cupo...\n",
       "2  Themes: Living|Nature\\nPoem:\\n\\n\\nLook for me ...\n",
       "3  Themes: Living|Nature\\nPoem:\\n\\n\\nBehind the s...\n",
       "4  Themes: Living|Relationships\\nPoem:\\n\\n\\nWhen ..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"poetry_text_dataset.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2dfd309-165f-433a-8b29-a0e9d9a99525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8136893f25c147adbfad9bfacbcace9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12446 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b4118da430459ebf797ac19a5919be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1383 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\comra\\anaconda3\\envs\\poetry-gen\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\comra\\AppData\\Local\\Temp\\ipykernel_49856\\155100765.py:48: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: comradev73 (comradev73-vit) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.3s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\comra\\Dev\\PoetryGeneration\\wandb\\run-20250406_125333-phsjgy0i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/comradev73-vit/huggingface/runs/phsjgy0i' target=\"_blank\">./poetry_gpt2_finetuned_continued</a></strong> to <a href='https://wandb.ai/comradev73-vit/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/comradev73-vit/huggingface' target=\"_blank\">https://wandb.ai/comradev73-vit/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/comradev73-vit/huggingface/runs/phsjgy0i' target=\"_blank\">https://wandb.ai/comradev73-vit/huggingface/runs/phsjgy0i</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3112' max='3112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3112/3112 1:15:44, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.286200</td>\n",
       "      <td>3.130330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.207100</td>\n",
       "      <td>3.129518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.203000</td>\n",
       "      <td>3.128995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.195300</td>\n",
       "      <td>3.128803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3112, training_loss=3.2204663686090385, metrics={'train_runtime': 4553.3206, 'train_samples_per_second': 10.934, 'train_steps_per_second': 0.683, 'total_flos': 1.3008162521088e+16, 'train_loss': 3.2204663686090385, 'epoch': 4.0})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, TextDataset, DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset, Dataset\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load your fine-tuned model checkpoint\n",
    "model_path = \"./poetry_gpt2_finetuned\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "\n",
    "df = pd.read_csv(\"poetry_text_dataset.csv\")\n",
    "\n",
    "dataset = Dataset.from_pandas(df[[\"text\"]])\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./poetry_gpt2_finetuned_continued\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=1e-5,\n",
    "    evaluation_strategy=\"epoch\",       \n",
    "    save_strategy=\"epoch\",             \n",
    "    logging_dir=\"./logs\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c567f1fb-ed15-4ced-8f3d-0bc13034d790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./poetry_gpt2_finetuned_continued\\\\tokenizer_config.json',\n",
       " './poetry_gpt2_finetuned_continued\\\\special_tokens_map.json',\n",
       " './poetry_gpt2_finetuned_continued\\\\vocab.json',\n",
       " './poetry_gpt2_finetuned_continued\\\\merges.txt',\n",
       " './poetry_gpt2_finetuned_continued\\\\added_tokens.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./poetry_gpt2_finetuned_continued\")\n",
    "tokenizer.save_pretrained(\"./poetry_gpt2_finetuned_continued\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abfc8b94-8057-416e-8226-cb71d2c143de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a theme for your poem (e.g., Love, Hope, Solitude):  Solitude,Sad,Depression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here's your poem:\n",
      "\n",
      "Someday I shall be free to go back and forth between those two.\n",
      "In this way we may never look into each otherâ€™s eyes again; The\n",
      "world is not all one.\n",
      "There are many things that must wait before me in order For\n",
      "happiness or sorrow I shall make my ownâ€”the heart has power\n",
      "over it\n",
      "And yet it does nothing but beat so hard At night till morning When\n",
      "its rhythm makes no sound But shifts its course and drifts like water.\n",
      "When pleasure grows strong enough then will joy grow weak?\n",
      "No!\n",
      "I have made peace with pain And found myself alone among some of them Who\n",
      "feel themselves as happy they were when you left home.\n",
      "This melancholy is what people say about their happiest moments, They\n",
      "say more than any sadness can ever bring Back.\n",
      "But for every unhappy thing there should also Be relief at ease In\n",
      "sleep where everything feels new and fresh Like\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import re\n",
    "import textwrap\n",
    "import spacy\n",
    "\n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def format_poem_poetically(poem, width=60):\n",
    "    poem = re.sub(r'\\s+', ' ', poem.strip())\n",
    "\n",
    "    doc = nlp(poem)\n",
    "    poetic_lines = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        words = sent.text.strip().split()\n",
    "        line = []\n",
    "        current_length = 0\n",
    "        i = 0\n",
    "\n",
    "        while i < len(words):\n",
    "            word = words[i]\n",
    "            line.append(word)\n",
    "            current_length += len(word) + 1  # +1 for space\n",
    "\n",
    "            if current_length >= width:\n",
    "                split_found = False\n",
    "                for j in range(i + 1, min(i + 6, len(words))):\n",
    "                    if re.search(r'[.,!?;:â€”]$', words[j]) or (words[j].istitle() and words[j] != \"I\"):\n",
    "                        poetic_lines.append(\" \".join(line + words[i+1:j+1]))\n",
    "                        i = j\n",
    "                        line = []\n",
    "                        current_length = 0\n",
    "                        split_found = True\n",
    "                        break\n",
    "\n",
    "                if not split_found:\n",
    "                    poetic_lines.append(\" \".join(line))\n",
    "                    line = []\n",
    "                    current_length = 0\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        if line:\n",
    "            poetic_lines.append(\" \".join(line))\n",
    "\n",
    "    return \"\\n\".join(poetic_lines).strip()\n",
    "\n",
    "def generate_poem(max_length=200):\n",
    "    model.eval()\n",
    "\n",
    "    theme = input(\"Enter a theme for your poem (e.g., Love, Hope, Solitude): \")\n",
    "\n",
    "    prompt = f\"Write a heartfelt and meaningful poem on the theme: {theme}\\nPoem:\\n\"\n",
    "\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            max_length=max_length,\n",
    "            do_sample=True,\n",
    "            temperature=0.8,\n",
    "            top_p=0.95,\n",
    "            top_k=40,\n",
    "            repetition_penalty=1.3,\n",
    "            num_return_sequences=1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            no_repeat_ngram_size=3\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    poem = generated_text.replace(prompt, \"\").strip()\n",
    "\n",
    "    poem = re.sub(r'(?<=[a-z])(?=[A-Z])', ' ', poem)  # Insert space between lowercase and uppercase\n",
    "    poem = re.sub(r'([.,!?;])(?=\\w)', r'\\1 ', poem)   \n",
    "\n",
    "    formatted_poem = format_poem_poetically(poem, width=60)\n",
    "\n",
    "    print(\"\\nHere's your poem:\\n\")\n",
    "    print(formatted_poem)\n",
    "\n",
    "# Run\n",
    "generate_poem()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15aeeccb-7cd8-40c9-b052-039d749d58b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.9772\n",
      "Perplexity: 19.6320\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "import math\n",
    "\n",
    "# Load fine-tuned model and tokenizer\n",
    "model_path = \"./poetry_gpt2_finetuned_continued\"  \n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "poem_text = \"\"\"The battle was always won or lost, and\n",
    "\n",
    "It always took a long time to get there.\n",
    "My father, who fought and lost,\n",
    "\n",
    "Struck his head back against the wall,\n",
    "I heard a shout as though\n",
    "\n",
    "He could hear me, but he could not.\n",
    "It took the day long, and I thought\n",
    "\n",
    "Of how my mother cried out,\n",
    "\"It's our day\"\"\"\n",
    "\n",
    "inputs = tokenizer(poem_text, return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, labels=input_ids)\n",
    "    loss = outputs.loss\n",
    "    perplexity = torch.exp(loss)\n",
    "\n",
    "print(f\"Loss: {loss.item():.4f}\")\n",
    "print(f\"Perplexity: {perplexity.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee2e104-90e5-4930-b123-9d6b79f0d80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating perplexities: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13829/13829 [11:35<00:00, 19.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Average Perplexity on dataset: 28.0797\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "model_path = \"./poetry_gpt2_finetuned_continued\"  # Update if your path differs\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.to(\"cuda\")\n",
    "\n",
    "df = pd.read_csv(\"poetry_text_dataset.csv\")  # Must contain a column named \"text\"\n",
    "texts = df['text'].dropna().tolist()\n",
    "\n",
    "def calculate_perplexity(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    if torch.cuda.is_available():\n",
    "        input_ids = input_ids.to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "    return math.exp(loss.item()) if loss.item() < 100 else float(\"inf\")  # Avoid overflow\n",
    "\n",
    "perplexities = []\n",
    "for text in tqdm(texts, desc=\"Calculating perplexities\"):\n",
    "    try:\n",
    "        ppl = calculate_perplexity(text)\n",
    "        perplexities.append(ppl)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing: {e}\")\n",
    "        perplexities.append(float(\"inf\"))\n",
    "\n",
    "# === Average Perplexity ===\n",
    "valid_ppls = [p for p in perplexities if p < float(\"inf\")]\n",
    "average_ppl = sum(valid_ppls) / len(valid_ppls)\n",
    "print(f\"\\nAverage Perplexity on dataset: {average_ppl:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03104790-e7e9-4a73-92ff-f8e5c8a5968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1191 poems to E:\\Datasets\\gutenberg_poems_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "input_file_path = \"C:\\\\Users\\\\comra\\\\Downloads\\\\gutenberg-poetry-v001.ndjson.gz\"\n",
    "output_csv_path = 'E:\\\\Datasets\\\\gutenberg_poems_cleaned.csv'\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation/special characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize whitespace\n",
    "    return text\n",
    "\n",
    "poems = defaultdict(list)\n",
    "\n",
    "with gzip.open(input_file_path, 'rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        entry = json.loads(line)\n",
    "        gid = entry['gid']\n",
    "        line_text = entry['s']\n",
    "        cleaned_line = clean_text(line_text)\n",
    "        if cleaned_line:  # Skip empty lines\n",
    "            poems[gid].append(cleaned_line)\n",
    "\n",
    "poem_texts = [' '.join(lines) for lines in poems.values()]\n",
    "\n",
    "df = pd.DataFrame({'Poem': poem_texts})\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(df)} poems to {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7972e3a5-712f-42cf-ae4b-74a0e27ed4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 99 labelled poems to labelled_abc_poems.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from torch.nn.functional import sigmoid\n",
    "import csv\n",
    "\n",
    "def load_poems_from_folder(folder_path):\n",
    "    poems = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
    "                content = file.read().strip()\n",
    "                if content:  # Skip empty files\n",
    "                    poems.append({'Poem': content})\n",
    "    return pd.DataFrame(poems)\n",
    "\n",
    "def predict_themes(df, model, tokenizer, label_list, max_length=512, threshold=0.5):\n",
    "    predicted_labels = []\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    for text in df['Poem']:\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_length)\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            probs = sigmoid(outputs.logits)[0].cpu().numpy()\n",
    "\n",
    "        labels = [label_list[i] for i, p in enumerate(probs) if p > threshold]\n",
    "\n",
    "        if not labels:\n",
    "            labels = [label_list[probs.argmax()]]\n",
    "\n",
    "        predicted_labels.append(\", \".join(labels))\n",
    "\n",
    "    df['Themes'] = predicted_labels\n",
    "    return df[['Poem', 'Themes']]\n",
    "\n",
    "def label_poems_in_folder(folder_path, output_csv_path, model_path, label_list):\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "    model = BertForSequenceClassification.from_pretrained(model_path, num_labels=len(label_list))\n",
    "\n",
    "    df = load_poems_from_folder(folder_path)\n",
    "\n",
    "    df = predict_themes(df, model, tokenizer, label_list)\n",
    "\n",
    "    df.to_csv(output_csv_path, index=False, quoting=csv.QUOTE_ALL)\n",
    "    print(f\"Saved {len(df)} labelled poems to {output_csv_path}\")\n",
    "\n",
    "folder_path = \"E:\\\\Datasets\\\\abc\"  # Folder with .txt files (each a poem)\n",
    "output_csv = \"labelled_abc_poems.csv\"\n",
    "model_path = \"./multi_label_theme_classifier\"  \n",
    "label_list = all_themes \n",
    "\n",
    "label_poems_in_folder(folder_path, output_csv, model_path, label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1a82c7df-137d-40c2-9d22-b80dcd4219c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Poem</th>\n",
       "      <th>Themes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 ABC of H.k. and China revised vision.\\nBarre...</td>\n",
       "      <td>Sorrow  Grieving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apparently life without love, is no life at al...</td>\n",
       "      <td>Love Lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A abc angles on angels flaws (poem)\\nMix with ...</td>\n",
       "      <td>Sorrow  Grieving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A abc Brazil dance (poem)\\nJack of crack in po...</td>\n",
       "      <td>Sorrow  Grieving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABC... I can't go on\\n123... what's the next o...</td>\n",
       "      <td>Men  Women</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Poem            Themes\n",
       "0  2 ABC of H.k. and China revised vision.\\nBarre...  Sorrow  Grieving\n",
       "1  Apparently life without love, is no life at al...         Love Lost\n",
       "2  A abc angles on angels flaws (poem)\\nMix with ...  Sorrow  Grieving\n",
       "3  A abc Brazil dance (poem)\\nJack of crack in po...  Sorrow  Grieving\n",
       "4  ABC... I can't go on\\n123... what's the next o...        Men  Women"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"labelled_abc_poems.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da766add-ebb2-458c-a8ea-c567a0f28bb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592fa25db5b444ffa66aa21c9f14064b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/89 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c9f75405bc4e169f8f77afc347714b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea3019549b246dbac1ac728cfced610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/99 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\comra\\AppData\\Local\\Temp\\ipykernel_49856\\2679718567.py:64: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 01:17, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.317100</td>\n",
       "      <td>3.980987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.983000</td>\n",
       "      <td>3.793307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.892800</td>\n",
       "      <td>3.709542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./poetry_gpt2_refined\\\\tokenizer_config.json',\n",
       " './poetry_gpt2_refined\\\\special_tokens_map.json',\n",
       " './poetry_gpt2_refined\\\\vocab.json',\n",
       " './poetry_gpt2_refined\\\\merges.txt',\n",
       " './poetry_gpt2_refined\\\\added_tokens.json')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_dir = \"./poetry_gpt2_finetuned_continued\"\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_dir, local_files_only=True)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_dir, local_files_only=True)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Load the labeled dataset\n",
    "df = pd.read_csv(\"labelled_abc_poems.csv\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, eval_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df[[\"text\"]])\n",
    "eval_dataset = Dataset.from_pandas(eval_df[[\"text\"]])\n",
    "\n",
    "tokenized_train = train_dataset.map(tokenize, batched=True)\n",
    "tokenized_eval = eval_dataset.map(tokenize, batched=True)\n",
    "\n",
    "def tokenize(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./poetry_gpt2_refined\",\n",
    "    overwrite_output_dir=True,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=4,\n",
    "    fp16=True,\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    learning_rate=5e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_eval,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"./poetry_gpt2_refined\")\n",
    "tokenizer.save_pretrained(\"./poetry_gpt2_refined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54c4d6d-507b-40a9-afba-3e9606571125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\comra\\anaconda3\\envs\\poetry-gen\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951418ab1f5c47e999e4111e3fa64abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/89 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592246cf49ae461689d73d92a652ac65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\comra\\anaconda3\\envs\\poetry-gen\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\comra\\AppData\\Local\\Temp\\ipykernel_25176\\3366341625.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: comradev73 (comradev73-vit) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.3s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\comra\\Dev\\PoetryGeneration\\wandb\\run-20250406_175838-e4c30h8c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/comradev73-vit/huggingface/runs/e4c30h8c' target=\"_blank\">./poetry_gpt2_v2</a></strong> to <a href='https://wandb.ai/comradev73-vit/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/comradev73-vit/huggingface' target=\"_blank\">https://wandb.ai/comradev73-vit/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/comradev73-vit/huggingface/runs/e4c30h8c' target=\"_blank\">https://wandb.ai/comradev73-vit/huggingface/runs/e4c30h8c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [135/135 00:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.334600</td>\n",
       "      <td>3.926764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.619800</td>\n",
       "      <td>3.785994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.738400</td>\n",
       "      <td>3.742439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./poetry_gpt2_v2\\\\tokenizer_config.json',\n",
       " './poetry_gpt2_v2\\\\special_tokens_map.json',\n",
       " './poetry_gpt2_v2\\\\vocab.json',\n",
       " './poetry_gpt2_v2\\\\merges.txt',\n",
       " './poetry_gpt2_v2\\\\added_tokens.json')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling, EarlyStoppingCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "df = pd.read_csv(\"labelled_abc_poems.csv\")\n",
    "def prepare_input(row):\n",
    "    themes = \", \".join(eval(row[\"Themes\"])) if isinstance(row[\"Themes\"], str) and row[\"Themes\"].startswith(\"[\") else row[\"Themes\"]\n",
    "    return f\"<|theme|> {themes} <|poem|> {row['Poem']}\"\n",
    "\n",
    "df[\"text\"] = df.apply(prepare_input, axis=1)\n",
    "\n",
    "df[\"text\"] = df[\"text\"].astype(str).str.strip()\n",
    "dataset = Dataset.from_pandas(df[[\"text\"]])\n",
    "\n",
    "model_path = \"./poetry_gpt2_finetuned_continued\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "train_test = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = train_test['train']\n",
    "eval_dataset = train_test['test']\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./poetry_gpt2_v2\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=5,\n",
    "    save_total_limit=2,\n",
    "    learning_rate=1e-5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    fp16=torch.cuda.is_available(),  # Enable mixed precision if GPU is available\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "#Trainer with EarlyStoppingCallback\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.save_model(\"./poetry_gpt2_v2\")\n",
    "tokenizer.save_pretrained(\"./poetry_gpt2_v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dd293b8-097f-4f98-aeb9-12c786754b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Poems:\n",
      "\n",
      "Poem 1:\n",
      "Write a heartfelt and meaningful poem on the Love, Romance, Relationships\n",
      "All-in-One\n",
      "   Love, Family & Family\n",
      "How a young man lives\n",
      "With love to his wife\n",
      "And his child\n",
      "A little girl\n",
      "A love we share,\n",
      "A life's worth\n",
      "Love to each of us\n",
      "Glorious and kind\n",
      "Beneath a love we cherish\n",
      "Beyond any earthly limits\n",
      "Came to him,\n",
      "He asked her to let him\n",
      "Hold his\n",
      "----------------------------------------\n",
      "Poem 2:\n",
      "Write a meaningful poem on the War, Hate, Life\n",
      "and Love that you are, and that you deserve,\n",
      "In the face of danger and danger,\n",
      "The poet shall be called a hero.\n",
      "I hope that your story will serve you well.\n",
      "Love will make you a hero again\n",
      "When it is time, when we need you most.\n",
      "You will never again be called an ordinary poet.\n",
      "Because when you are on the run,\n",
      "Sometimes you will die. You will\n",
      "----------------------------------------\n",
      "Poem 3:\n",
      "Write a accurate poem on the Living, Hope, Love, Relationships\n",
      "Like a poet whoâ€™d read this poem,\n",
      "Love, but only if one can read\n",
      "Loveâ€™s poems to make a living,\n",
      "But only if a poet can read them in his own language.\n",
      "If he can read and read and even write,\n",
      "He could easily make a name for himself\n",
      "If one has a good love for him.\n",
      "Therefore, read this in your poem and if\n",
      "----------------------------------------\n",
      "Poem 4:\n",
      "Write a creative and meaningful poem on the Family, or go for a walk across the street.\n",
      "And when you are done, you will need to find a new book, and you will want to keep the book but don't write it down as soon as possible.\n",
      "The books you have are for a different time and are made of different materials.\n",
      "Do not take the chance of an unexpected book after all!\n",
      "You will need a new story, a new way of thinking, a good\n",
      "----------------------------------------\n",
      "Poem 5:\n",
      "Write a perfect poem on the Science & Politics Facebook page.\n",
      "Afterwords are spent, as always the world is in full swing,\n",
      "A race will be won or lost on the field,\n",
      "Afternoon is done and the play is just started.\n",
      "This is what our time of peace is like.\n",
      "It can be rough, it can be difficult.\n",
      "The field will be full, there will be no play,\n",
      "And every play will be the same,\n",
      "We will all win\n",
      "----------------------------------------\n",
      "Poem 6:\n",
      "Write a heartfelt and meaningful poem on the Love, Romance, Relationships, Social Commentaries\n",
      "Like a poet, or in any other language\n",
      "Would you write a love poem on Love, Love, Relationsences?\n",
      "Love, Romance is my passion,\n",
      "My love is my life, and it is my hope.\n",
      "Love is like my life: the world is made up of words,\n",
      "Everything I say or write is meant to say\n",
      "Love will always be at the heart of my heart\n",
      "----------------------------------------\n",
      "Poem 7:\n",
      "Write a meaningful poem on the War, Hate War and Loss.\n",
      "\n",
      "The battle was always won or lost, and\n",
      "\n",
      "It always took a long time to get there.\n",
      "My father, who fought and lost,\n",
      "\n",
      "Struck his head back against the wall,\n",
      "I heard a shout as though\n",
      "\n",
      "He could hear me, but he could not.\n",
      "It took the day long, and I thought\n",
      "\n",
      "Of how my mother cried out,\n",
      "\"It's our day\n",
      "----------------------------------------\n",
      "Poem 8:\n",
      "Write a accurate poem on the Living, Hope, Love Story.\n",
      "    When you say something good to the world, then your poem is going to be a real treasure!\n",
      "  So let's give your heart a chance!\n",
      "But it isn't your fault the people don't like you.\n",
      "So get the big picture!\n",
      "Your poem is not going to stand up to the bully\n",
      "  But he is right, as you are reading the letter.\n",
      "You are telling them\n",
      "----------------------------------------\n",
      "Poem 9:\n",
      "Write a creative and meaningful poem on the Family Tries. If you like it and feel free to donate.If you don't, please don't.    * * *\n",
      "â€œItâ€™s not funny.â€ It makes my skin crawl. â€œIt makes my brain thinkâ€ my heart will pump up blood. I know the pain of being an animal. I have a good heart. I donâ€™t get sad and jump when I hear about animals\n",
      "----------------------------------------\n",
      "Poem 10:\n",
      "Write a perfect poem on the Science & Politics section of The New York Times. The world is still in turmoil. This is a poem of peace. But, don't try to go along, don|t try to stay silent, don not try to say anything. I am writing here to you. â€œOneâ€ means the same as â€œ2â€. â€A\" means â€œandâ€ forâ€œ2 andâ€, oneâ€™sâ€™\n",
      "----------------------------------------\n",
      "\n",
      "Perplexities:\n",
      "Poem 1: 18.13\n",
      "Poem 2: 16.74\n",
      "Poem 3: 15.75\n",
      "Poem 4: 14.50\n",
      "Poem 5: 15.42\n",
      "Poem 6: 13.54\n",
      "Poem 7: 18.47\n",
      "Poem 8: 21.89\n",
      "Poem 9: 15.46\n",
      "Poem 10: 14.44\n",
      "Average Perplexity: 16.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERTScore (F1):\n",
      "Poem 1: 0.8009\n",
      "Poem 2: 0.8098\n",
      "Poem 3: 0.8148\n",
      "Poem 4: 0.8108\n",
      "Poem 5: 0.8063\n",
      "Poem 6: 0.8170\n",
      "Poem 7: 0.8103\n",
      "Poem 8: 0.8211\n",
      "Poem 9: 0.8035\n",
      "Poem 10: 0.8091\n",
      "Average BERTScore (F1): 0.8104\n",
      "\n",
      "Thematic Coherence (Binary Labels):\n",
      "Poem 1 Themes: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Poem 2 Themes: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Poem 3 Themes: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Poem 4 Themes: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Poem 5 Themes: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Poem 6 Themes: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Poem 7 Themes: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Poem 8 Themes: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Poem 9 Themes: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Poem 10 Themes: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TextGenerationPipeline\n",
    "import torch\n",
    "import math\n",
    "import evaluate\n",
    "\n",
    "model_path = \"./poetry_gpt2_refined\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path).to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def calculate_perplexity(model, tokenizer, texts):\n",
    "    model.eval()\n",
    "    perplexities = []\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "            outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "            loss = outputs.loss\n",
    "            perplexity = torch.exp(loss).item()\n",
    "            perplexities.append(perplexity)\n",
    "    return perplexities\n",
    "\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "\n",
    "generator = TextGenerationPipeline(model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n",
    "prompts = [\"Write a heartfelt and meaningful poem on the Love, Romance\",\n",
    "           \"Write a meaningful poem on the War, Hate\",\n",
    "           \"Write a accurate poem on the Living, Hope\",\n",
    "           \"Write a creative and meaningful poem on the Family\",\n",
    "           \"Write a perfect poem on the Science\",\n",
    "           \"Write a heartfelt and meaningful poem on the Love, Romance\",\n",
    "           \"Write a meaningful poem on the War, Hate\",\n",
    "           \"Write a accurate poem on the Living, Hope\",\n",
    "           \"Write a creative and meaningful poem on the Family\",\n",
    "           \"Write a perfect poem on the Science\"\n",
    "            ]\n",
    "generated_poems = [generator(prompt, max_length=100, num_return_sequences=1, do_sample=True, top_p=0.95, no_repeat_ngram_size=3)[0]['generated_text'] for prompt in prompts]\n",
    "\n",
    "print(\"\\nGenerated Poems:\\n\")\n",
    "for i, poem in enumerate(generated_poems):\n",
    "    print(f\"Poem {i+1}:\\n{poem}\\n{'-'*40}\")\n",
    "\n",
    "#  Calculate Perplexity\n",
    "perplexities = calculate_perplexity(model, tokenizer, generated_poems)\n",
    "print(\"\\nPerplexities:\")\n",
    "for i, p in enumerate(perplexities):\n",
    "    print(f\"Poem {i+1}: {p:.2f}\")\n",
    "avg_perplexity = sum(perplexities) / len(perplexities)\n",
    "print(f\"Average Perplexity: {avg_perplexity:.2f}\")\n",
    "\n",
    "references = [\"I gaze upon the night sky filled with stars\", \n",
    "              \"The silence of gardens brings peace\",\n",
    "              \"A voice in the dark calls my name\",\n",
    "              \"Love burns without control\",\n",
    "              \"Hope is all I have left\",\n",
    "              \"I gaze upon the night sky filled with stars\", \n",
    "              \"The silence of gardens brings peace\",\n",
    "              \"A voice in the dark calls my name\",\n",
    "              \"Love burns without control\",\n",
    "              \"Hope is all I have left\"\n",
    "             ]\n",
    "\n",
    "bertscore_result = bertscore.compute(predictions=generated_poems, references=references, lang=\"en\")\n",
    "print(\"\\nBERTScore (F1):\")\n",
    "for i, score in enumerate(bertscore_result[\"f1\"]):\n",
    "    print(f\"Poem {i+1}: {score:.4f}\")\n",
    "avg_bert = sum(bertscore_result[\"f1\"]) / len(bertscore_result[\"f1\"])\n",
    "print(f\"Average BERTScore (F1): {avg_bert:.4f}\")\n",
    "\n",
    "# Thematic Coherence (using theme classifier)\n",
    "theme_classifier_path = \"./multi_label_theme_classifier\"\n",
    "theme_model = AutoModelForSequenceClassification.from_pretrained(theme_classifier_path).to(device)\n",
    "theme_tokenizer = AutoTokenizer.from_pretrained(theme_classifier_path)\n",
    "\n",
    "def predict_themes(texts):\n",
    "    theme_model.eval()\n",
    "    theme_labels = []\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            inputs = theme_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "            logits = theme_model(**inputs).logits\n",
    "            probs = torch.sigmoid(logits)\n",
    "            labels = (probs > 0.5).int().tolist()[0]\n",
    "            theme_labels.append(labels)\n",
    "    return theme_labels\n",
    "\n",
    "theme_predictions = predict_themes(generated_poems)\n",
    "print(\"\\nThematic Coherence (Binary Labels):\")\n",
    "for i, labels in enumerate(theme_predictions):\n",
    "    print(f\"Poem {i+1} Themes: {labels}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95846a4c-92c5-45a3-af24-5ddb9c17039f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "model_path = \"./poetry_gpt2_v2\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path).to(device)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # for safety\n",
    "\n",
    "def format_poem(poem, width=60):\n",
    "\n",
    "    poem = re.sub(r'[*_~`<>\\\\|#^]', '', poem)\n",
    "    poem = re.sub(r'\\s+', ' ', poem.strip())\n",
    "    poem = re.sub(r'\\.{2,}', '.', poem)\n",
    "\n",
    "    doc = nlp(poem)\n",
    "    poetic_lines = []\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        words = sent.text.strip().split()\n",
    "        line = []\n",
    "        current_length = 0\n",
    "        i = 0\n",
    "\n",
    "        while i < len(words):\n",
    "            word = words[i]\n",
    "            line.append(word)\n",
    "            current_length += len(word) + 1\n",
    "\n",
    "            if current_length >= width:\n",
    "                split_point = len(line)\n",
    "                for k in reversed(range(len(line))):\n",
    "                    if re.search(r'[.,!?;:â€”]$', line[k]) or (line[k].istitle() and line[k] != \"I\"):\n",
    "                        split_point = k + 1\n",
    "                        break\n",
    "\n",
    "                new_line = \" \".join(line[:split_point])\n",
    "                if len(new_line.strip()) > 3:  \n",
    "                    poetic_lines.append(new_line)\n",
    "\n",
    "                i = i - len(line) + split_point\n",
    "                line = []\n",
    "                current_length = 0\n",
    "            i += 1\n",
    "\n",
    "        if line:\n",
    "            new_line = \" \".join(line)\n",
    "            if len(new_line.strip()) > 3:\n",
    "                poetic_lines.append(new_line)\n",
    "\n",
    "    if poetic_lines and len(poetic_lines[-1]) < width // 2:\n",
    "        poetic_lines.pop()\n",
    "\n",
    "    return \"\\n\".join(poetic_lines).strip()\n",
    "\n",
    "\n",
    "\n",
    "# Main generation function\n",
    "def generate_poem(theme, max_length=150):\n",
    "    model.eval()\n",
    "    prompt = f\"Write a poetic piece that uses rich imagery, emotional depth, and lyrical language on the theme: {theme}\\nPoem:\\n\"\n",
    "\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "    attention_mask = input_ids.ne(tokenizer.pad_token_id).long()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            do_sample=True,\n",
    "            temperature=0.85,\n",
    "            top_p=0.92,\n",
    "            top_k=40,\n",
    "            max_new_tokens=150,\n",
    "            repetition_penalty=1.2,\n",
    "            num_return_sequences=3,\n",
    "            no_repeat_ngram_size=3,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    if not generated_text or prompt not in generated_text:\n",
    "        return \"Something went wrong while generating the poem. Please try again with a different theme.\"\n",
    "\n",
    "    poem = generated_text.replace(prompt, \"\").strip()\n",
    "    poem = re.sub(r'(?<=[a-z])(?=[A-Z])', ' ', poem)\n",
    "    poem = re.sub(r'([.,!?;])(?=\\w)', r'\\1 ', poem)\n",
    "\n",
    "    return format_poem(poem)\n",
    "\n",
    "# Gradio UI\n",
    "demo = gr.Interface(\n",
    "    fn=generate_poem,\n",
    "    inputs=gr.Textbox(label=\"Enter Theme\", placeholder=\"Type your own theme here...\"),\n",
    "    outputs=gr.Textbox(label=\"Generated Poem\", lines=10),\n",
    "    title=\"Poetry Generator ðŸŽ­\",\n",
    "    description=\"Enter a theme and generate a poem \"\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19217814-2f98-4b70-b8bf-a4fbdc0ed3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (poetry-gen)",
   "language": "python",
   "name": "poetry-gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
